#!/bin/bash

if [ -z "$1" ]
  then echo "Please provide the name of the game and a log name and a port, e.g.  
  ./run_gpu montezuma_revenge basic1 5550 <optional subgoal> <optional use_distance> <optional eps_endt> <optional lr>"; exit 0
fi

subgoal_index=${4:-12} # a number between 2 to 11 for now, 12 means not use any subgoal
use_distance=${5:-true} #using distance to subgoal as a reward


ENV=$1
FRAMEWORK="alewrap"
game_path=$PWD"/roms/"
env_params="useRGB=true"
agent="NeuralQLearner"
n_replay=1
netfile="\"convnet_atari3\""
# netfile="\"golden.t7\""
update_freq=4
actrep=4
discount=0.99
discount_internal=0.99
dynamic_discount=0.99  #starting value for dynamic discounting scheme
seed=$3 #using port as seed
learn_start=1200 #50000 #100
meta_learn_start=1000 #50000 #100

pool_frms_type="\"max\""
pool_frms_size=2
initial_priority="false"
replay_memory=1000000
eps_end=0.1 #0.1
eps_endt=${6:-200000} #500000 #replay_memory
lr=${7:-0.00025} #0.00025
lr_meta=0.0005
agent_type=$2
preproc_net="\"net_downsample_2x_full_y\""
agent_name=$agent_type"_"$1
state_dim=7056
ncols=1
minibatch_size=32
total_subgoals=2 #corresponds to number of images in expert/ folder

agent_params="total_subgoals="$total_subgoals",use_distance="$use_distance",lr="$lr",lr_meta="$lr_meta",ep=1,ep_end="$eps_end",ep_endt="$eps_endt",dynamic_discount="$dynamic_discount",discount="$discount",discount_internal="$discount_internal",hist_len=4,learn_start="$learn_start",meta_learn_start="$meta_learn_start",replay_memory="$replay_memory",update_freq="$update_freq",n_replay="$n_replay",network="$netfile",preproc="$preproc_net",state_dim="$state_dim",minibatch_size=$minibatch_size,rescale_r=1,ncols="$ncols",valid_size=500,target_q=10000,clip_delta=10,min_reward=-1000,max_reward=1000"
steps=50000000
eval_freq=30000
eval_steps=10000
prog_freq=10000
save_freq=10000
gpu=0
random_starts=1  #need to make this 30 later for random starting points for comparison with original DQN
pool_frms="type="$pool_frms_type",size="$pool_frms_size
num_threads=4

mkdir dqn/logs/$agent_type;
args="-framework $FRAMEWORK -exp_folder logs/$agent_type -game_path $game_path -name logs/$agent_type/$agent_name -env $ENV -env_params $env_params -agent $agent -agent_params $agent_params -steps $steps -eval_freq $eval_freq -eval_steps $eval_steps -prog_freq $prog_freq -save_freq $save_freq -actrep $actrep -gpu $gpu -random_starts $random_starts -pool_frms $pool_frms -seed $seed -threads $num_threads -port $3 -subgoal_index $subgoal_index"
echo $args

cd dqn
th train_agent.lua $args
